###########
#Table 3.2/3.3
#######
#########
#ordinary least square model/ OLS

View(spamTrain)
spamTrain$row.names=NULL
p=dim(spamTrain)[2]-1
nrow=nrow(spamTrain)

X = spamTrain[,1:p] # get the predictor data

# Append a column of ones:
# 
Dp = cbind( matrix(1,nrow,1), as.matrix( X ) )
response=apply(as.matrix(spamTrain[,p+1]),1,function(x) {ifelse(x=='spam',1,0)})

library(MASS)
betaHat = ginv( t(Dp) %*% Dp ) %*% t(Dp) %*% as.matrix(response)

# this is basically the first column in Table 3.2:
#
print('first column: beta estimates')
print(betaHat,digits=2)

# make predictions based on these estimated beta coefficients:
#
yhat = Dp %*% betaHat 

# estimate the variance:
# 
sigmaHat = sum( ( response - yhat )^2 ) / ( nrow - p - 1 )

# calculate the covariance of betaHat:
#
covarBetaHat = sigmaHat * ginv( t(Dp) %*% Dp ) 

# calulate the standard deviations of betahat:
#
stdBetaHat = sqrt(diag(covarBetaHat))

# this is basically the second column in Table 3.2:
#
print('second column: beta standard errors')
print( as.matrix(stdBetaHat), digits=2 )

# compute the z-scores:
#
z = betaHat / stdBetaHat 

# this is basically the third column in Table 3.2:
#
print('third column: beta z-scores')
print( z, digits=2 )

# display the results we get : 
F = data.frame( Term=c("Intercept",names(spamTrain)[1:p]), Coefficients=betaHat, Std_Error=stdBetaHat, Z_Score=z )
#install.packages("xtable")
library(xtable)
xtable( F, caption="Table of OLS coefficients for the SPAM data set", digits=2 ) 

# Run this full linear model on the Testing data so that we can fill in the two
# lower spots in the "LS" column in Table 3.2
#
pdt = cbind( matrix(1,dim(spamTest)[1],1), as.matrix( spamTest[,1:p] ) ) %*% betaHat 
responseTest = apply(as.matrix(spamTest[,p+1]),1,function(x) {ifelse(x=='spam',1,0)})
NTest = length(responseTest)
mErr = mean( (responseTest - pdt)^2 )
print( mErr ) 
sErr = sqrt( var( (responseTest - pdt)^2 )/NTest ) 
print( sErr )

#####
#Ridge Regression, see example Linear regression
#####
library(glmnet)

fit.ridge<-glmnet(as.matrix(spamTrain[,1:p]),spamTrain$A.58,alpha=0,family = "binomial")
plot(fit.ridge)
print(fit.ridge)
coef(fit.ridge,s=0.01)
fit.ridge.cv = cv.glmnet(as.matrix(spamTrain[,1:p]),spamTrain$A.58,alpha=0,family = "binomial")
plot(fit.ridge.cv)


#####
#Lasso Regression, see example Linear regression
#####
library(glmnet)

fit.lasso<-glmnet(as.matrix(spamTrain[,1:p]),spamTrain$A.58,family = "binomial")
plot(fit.lasso)
print(fit.lasso)
coef(fit.lasso,s=1.630e-01)
fit.lasso.cv = cv.glmnet(as.matrix(spamTrain[,1:p]),spamTrain$A.58,family = "binomial")
plot(fit.lasso.cv)

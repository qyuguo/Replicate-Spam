###################################
###Boosting trees Chapter10

#install.packages("gbm")
library(gbm)
p = dim(spam)[2]-1 # the last column is the response 1=>Spam; 0=>Ham
spamTrain[,p+1]=apply(as.matrix(spamTrain[,p+1]),1,function(x) {ifelse(x=='spam',1,0)})
spamTest[,p+1]=apply(as.matrix(spamTest[,p+1]),1,function(x) {ifelse(x=='spam',1,0)})
colnames(spamTrain)[p+1] = "Y"
#colnames(spamTrain)[1:p]=spam_words
colnames(spamTest)[p+1] = "Y"
#colnames(spamTest)[1:p]=spam_words



# Generate the formula used to fit our model with: 
#
terms = paste( colnames(spamTrain)[1:p], collapse="+" ) # dont consider the last column (the response variable)
formula = formula( paste( colnames(spamTrain)[p+1], " ~ ", terms ) )

n_trees = 50000
K = 3 # larger values of K can give different performance
m = gbm( formula, data=spamTrain, distribution='bernoulli', n.trees=n_trees, shrinkage=0.005, interaction.depth=K, verbose=TRUE, cv.folds=5 )
gbm.perf(m,method="cv")

# This works but I think the default method of gbm.perf(m,method="cv")
# provides a better esimate of performance as a function of boosting iteration : 
# 
if( FALSE ){ 
    # Simple sanity check that our algorithm is working correctly (plot training as a function of number of boosts): 
    #
    training_error = matrix( 0, nrow=n_trees, ncol=1 )
    for( nti in seq(1,n_trees) ){
      Fhat = predict( m, XTraining[,1:p], n.trees=nti )
      pcc = mean( ( ( Fhat <= 0 ) & ( XTraining[,p+1] == 0 ) ) | ( ( Fhat > 0 ) & ( XTraining[,p+1] == 1 ) ) )
      training_error[nti] = 1 - pcc
    }

    # Lets plot the testing error as a function of the number of trees:
    #
    test_error = matrix( 0, nrow=n_trees, ncol=1 )
    for( nti in seq(1,n_trees) ){
      Fhat = predict( m, XTesting[,1:p], n.trees=nti )
      pcc = mean( ( ( Fhat <= 0 ) & ( XTesting[,p+1] == 0 ) ) | ( ( Fhat > 0 ) & ( XTesting[,p+1] == 1 ) ) )
      test_error[nti] = 1 - pcc 
    }

    plot( seq(1,n_trees), training_error, type="l", main="Boosting Probability of Error", col="red", xlab="number of boosting iterations", ylab="classification error" )
    lines( seq(1,n_trees), test_error, type="l", col="green" )

    legend( 700, 0.4, c("training error", "testing error"), col=c("red", "green"), lty=c(1,1) )
}

# Look at the learning curves (estimated via cross validation) and determine the best number of boosting trees to use:
# 
#postscript("../../WriteUp/Graphics/Chapter10/dup_spam_learning_curves_K_3.eps", onefile=FALSE, horizontal=FALSE)
best.iter = gbm.perf(m,method="cv")
#dev.off()

# Plot the relative importance of each word used in the classification:
